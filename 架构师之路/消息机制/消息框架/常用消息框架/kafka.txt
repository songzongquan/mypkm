Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2018-08-09T11:00:24+08:00

====== kafka ======
Created 星期四 09 八月 2018

ApacheKafka®是一个分布式流媒体平台。这到底是什么意思呢？
流媒体平台有三个关键功能：

发布和订阅记录流，类似于消息队列或企业消息传递系统。
以容错的持久方式存储记录流。
记录发生时处理流。
Kafka通常用于两大类应用：

构建可在系统或应用程序之间可靠获取数据的实时流数据管道
构建转换或响应数据流的实时流应用程序
要了解Kafka如何做这些事情，让我们深入探讨Kafka的能力。

首先是几个概念：

Kafka作为一个集群运行在一个或多个可跨多个数据中心的服务器上。
Kafka集群以称为主题的类别存储记录流。
每条记录都包含一个键，一个值和一个时间戳。
Kafka有四个核心API：

该制片API允许应用程序发布的记录流至一个或多个卡夫卡的话题。
该消费者API允许应用程序订阅一个或多个主题，并处理所产生的对他们记录的数据流。
所述流API允许应用程序充当流处理器，从一个或多个主题消耗的输入流，并产生一个输出流至一个或多个输出的主题，有效地变换所述输入流，以输出流。
该连接器API允许构建和运行卡夫卡主题连接到现有的应用程序或数据系统中重用生产者或消费者。例如，关系数据库的连接器可能捕获对表的每个更改。


====== 核心概念 ======

通常来讲，消息模型可以分为两种：队列和发布-订阅式。队列的处理方式是一组消费者从服务器读取消息，一条消息只有其中的一个消费者来处理。在发布-订阅模型中，消息被广播给所有的消费者，接收到消息的消费者都可以处理此消息。Kafka为这两种模型提供了单一的消费者抽象模型： 消费者组(consumer group)。消费者用一个消费者组名标记自己。

	   一个发布在Topic上消息被分发给此消费者组中的一个消费者。假如所有的消费者都在一个组中，那么这就变成了queue模型。假如所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型。更通用的， 我们可以创建一些消费者组作为逻辑上的订阅者。每个组包含数目不等的消费者，一个组内多个消费者可以用来扩展性能和容错。       

	   并且，kafka能够保证生产者发送到一个特定的Topic的分区上，消息将会按照它们发送的顺序依次加入，也就是说，如果一个消息M1和M2使用相同的producer发送，M1先发送，那么M1将比M2的offset低，并且优先的出现在日志中。消费者收到的消息也是此顺序。如果一个Topic配置了复制因子（replication facto）为N,那么可以允许N-1服务器宕机而不丢失任何已经提交（committed）的消息。此特性说明kafka有比传统的消息系统更强的顺序保证。但是，相同的消费者组中不能有比分区更多的消费者，否则多出的消费者一直处于空等待，不会收到消息。
1.4 kafka应用场景
	   构建实时的流数据管道，可靠地获取系统和应用程序之间的数据。
	   构建实时流的应用程序，对数据流进行转换或反应。

1.5 主题和日志 (Topic和Log)

	  每一个分区(partition)都是一个顺序的、不可变的消息队列,并且可以持续的添加。分区中的消息都被分了一个序列号,称之为偏移量(offset),在每个分区中此偏移量都是唯一的。Kafka集群保持所有的消息,直到它们过期,无论消息是否被消费了。实际上消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置。 这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，消费者可以将偏移量重置为更老的一个偏移量，重新读取消息。 可以看到这种设计对消费者来说操作自如， 一个消费者的操作不会影响其它消费者对此log的处理。 再说说分区。Kafka中采用分区的设计有几个目的。一是可以处理更多的消息，不受单台服务器的限制。Topic拥有多个分区意味着它可以不受限的处理更多的数据。第二，分区可以作为并行处理的单元，稍后会谈到这一点。

1.6 分布式(Distribution)

	   Log的分区被分布到集群中的多个服务器上。每个服务器处理它分到的分区。根据配置每个分区还可以复制到其它服务器作为备份容错。 每个分区有一个leader，零或多个follower。Leader处理此分区的所有的读写请求，而follower被动的复制数据。如果leader宕机，其它的一个follower会被推举为新的leader。 一台服务器可能同时是一个分区的leader，另一个分区的follower。 这样可以平衡负载，避免所有的请求都只让一台或者某几台服务器处理


==== topic ====
就是消息记录流的分类,  发消息时可以指定topic,topic必须事先存在才行.
每条记录都有一个键,值和时间戳


===== key =====
记录的键

==== value ====
记录有一个值

==== 时间戳 ====
记录的时间 戳


==== 分区Partition ====
  物理概念,每一个topic 下挂多个分区.


==== 消费者组 Consumer Group ====

每一个消费者属于一个组, 没指定属于缺省组.
kafka用组来简化 统一了消息模型, 消费者属于一个组,不是点对点,队列模式, 每一个消息费一个组,就是发布-订阅模式.

===== 安装与配置 =====




===== 客户端api与命令 =====

=== 命令 ===
1. 创建topic:  bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 3 --topic test    


参考资料:
https://www.cnblogs.com/cyfonly/p/5954614.html
